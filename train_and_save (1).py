# -*- coding: utf-8 -*-
"""train_and_save

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OsJSiwt6WYBTtCbItkuLvbR7DSqPzaDK
"""

import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
import joblib
import numpy as np
import warnings

warnings.filterwarnings('ignore')

# Download the dataset
!wget -O Titanic_train.csv https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv

# 1. Load Data
try:
    # This assumes 'Titanic_train.csv' is in the same directory.
    df = pd.read_csv('Titanic_train.csv')
except FileNotFoundError:
    print("Error: 'Titanic_train.csv' not found. Please ensure it's in the same directory.")
    # Exit or handle the error appropriately, perhaps raise the exception again
    raise

# Check if df is defined before proceeding
if 'df' in locals():
    # 2. Data Preprocessing (Mirroring steps from the Jupyter Notebook)

    # Impute 'Age' with median
    df['Age'].fillna(df['Age'].median(), inplace=True)

    # Drop 'Cabin'
    df.drop('Cabin', axis=1, inplace=True)

    # Impute 'Embarked' with mode
    df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)

    # Label Encode 'Sex'
    le = LabelEncoder()
    df['Sex'] = le.fit_transform(df['Sex'])

    # One-Hot Encode 'Embarked'
    df = pd.get_dummies(df, columns=['Embarked'], drop_first=True, dtype=int)

    # Process 'Ticket' column
    df['Tickets'] = df['Ticket'].apply(lambda x: str(x).split()[-1])
    df['Tickets'] = pd.to_numeric(df['Tickets'], errors='coerce')
    # Drop original 'Ticket'
    df.drop('Ticket', axis=1, inplace=True)

    # Impute NaN values in the newly created 'Tickets' column with the median (added for robustness)
    df['Tickets'].fillna(df['Tickets'].median(), inplace=True)


    # 3. Prepare Features and Target
    X = df.drop(['PassengerId', 'Survived', 'Name'], axis=1)
    y = df['Survived']

    # 4. Feature Scaling and Model Training
    # Identify columns to scale
    numerical_cols = ['Age', 'Fare', 'Tickets']
    scaler = StandardScaler()
    X[numerical_cols] = scaler.fit_transform(X[numerical_cols])

    # Train Logistic Regression Model
    model = LogisticRegression(solver='liblinear', random_state=42)
    model.fit(X, y)

    # 5. Save the fitted Scaler and Model
    joblib.dump(scaler, 'scaler.joblib')
    joblib.dump(model, 'logistic_regression_model.joblib')

    print("Model and Scaler successfully trained and saved as 'logistic_regression_model.joblib' and 'scaler.joblib'.")
else:
    print("DataFrame 'df' was not created due to a file loading error.")